x-airflow-common: &airflow-common
  build:
    context: ./airflow
  environment:
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    AIRFLOW__CORE__LOAD_EXAMPLES: "False"
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "False"
    AIRFLOW__CORE__DEFAULT_TIMEZONE: Asia/Seoul
    AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "True"
    AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: "True"
    KAFKA_BOOTSTRAP_SERVERS: kafka:9092
    NAVER_CLIENT_ID: ${NAVER_CLIENT_ID}
    NAVER_CLIENT_SECRET: ${NAVER_CLIENT_SECRET}
  volumes:
    - ./airflow/dags:/opt/airflow/dags
    - ./airflow:/opt/airflow/airflow
    - ./kafka:/opt/airflow/kafka    # producer 모듈 import 경로
    - airflow_logs:/opt/airflow/logs
    - airflow_plugins:/opt/airflow/plugins
  dns:
    - 8.8.8.8
    - 8.8.4.4
  user: "${AIRFLOW_UID:-50000}:0"
  depends_on:
    postgres:
      condition: service_healthy
    kafka:
      condition: service_healthy

services:
  # ──────────────────────────────────────────────
  # Kafka 스택
  # ──────────────────────────────────────────────
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.0
    hostname: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:7.6.0
    hostname: kafka
    depends_on:
      - zookeeper
    ports:
      - "29092:29092"   # 로컬 디버깅용 (host → localhost:29092)
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092 2>/dev/null | head -1"]
      interval: 10s
      timeout: 10s
      retries: 15
      start_period: 30s

  kafka-init:
    image: confluentinc/cp-kafka:7.6.0
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      - ./kafka/init-topics.sh:/init-topics.sh
    entrypoint: ["/bin/bash", "/init-topics.sh"]
    restart: "no"

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    ports:
      - "8085:8080"   # 호스트 8085 → 컨테이너 8080
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
    depends_on:
      kafka:
        condition: service_healthy

  # ──────────────────────────────────────────────
  # MySQL 스택
  # ──────────────────────────────────────────────
  mysql:
    image: mysql:8.0
    hostname: mysql
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_DATABASE: blog_db
    volumes:
      - mysql_data:/var/lib/mysql
      - ./mysql/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "3307:3306"   # WSL2 환경에서 3306 충돌 방지 (호스트에서 localhost:3307 으로 접속)
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-proot"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s

  blog-consumer:
    build:
      context: ./kafka
      dockerfile: Dockerfile.consumer
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      KAFKA_TOPIC: blog.raw
      KAFKA_GROUP_ID: blog-raw-mysql-sink
      KAFKA_AUTO_OFFSET_RESET: earliest
      MYSQL_HOST: mysql
      MYSQL_PORT: 3306
      MYSQL_DATABASE: blog_db
      MYSQL_USER: root
      MYSQL_PASSWORD: root
    depends_on:
      kafka:
        condition: service_healthy
      mysql:
        condition: service_healthy
    restart: unless-stopped

  # ──────────────────────────────────────────────
  # Airflow 스택
  # ──────────────────────────────────────────────
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - airflow_postgres:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 5s
      timeout: 5s
      retries: 10

  airflow-init:
    <<: *airflow-common
    command: >
      bash -lc "airflow db migrate &&
      airflow users create --username admin --password admin --firstname admin --lastname admin --role Admin --email admin@example.com || true"
    restart: "no"

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    restart: always

  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - "8080:8080"
    restart: always

  # ──────────────────────────────────────────────
  # Flink + Redis 스택
  # ──────────────────────────────────────────────
  redis:
    image: redis:7-alpine
    hostname: redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 10

  flink-jobmanager:
    build:
      context: ./flink
    hostname: flink-jobmanager
    command: jobmanager
    ports:
      - "8081:8081"
    environment:
      JOB_MANAGER_RPC_ADDRESS: flink-jobmanager
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      KAFKA_TOPIC: blog.cleaned
      KAFKA_GROUP_ID: flink-traffic-10m
      KAFKA_STARTING_OFFSETS: latest
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_DB: 0
      REDIS_KEY: trend:traffic:10m
    volumes:
      - ./flink/traffic_10m_to_redis_job.py:/opt/flink/usrlib/traffic_10m_to_redis_job.py
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy

  flink-taskmanager:
    build:
      context: ./flink
    hostname: flink-taskmanager
    command: taskmanager
    environment:
      JOB_MANAGER_RPC_ADDRESS: flink-jobmanager
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      KAFKA_TOPIC: blog.cleaned
      KAFKA_GROUP_ID: flink-traffic-10m
      KAFKA_STARTING_OFFSETS: latest
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_DB: 0
      REDIS_KEY: trend:traffic:10m
    volumes:
      - ./flink/traffic_10m_to_redis_job.py:/opt/flink/usrlib/traffic_10m_to_redis_job.py
    depends_on:
      flink-jobmanager:
        condition: service_started
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy

volumes:
  airflow_postgres:
  airflow_logs:
  airflow_plugins:
  redis_data:
  mysql_data:
